import json
import os
import gradio as gr
from dotenv import load_dotenv
import asyncio
import mongodb_atlas_retriever_tools
import boto3
from gradio import Markdown as m

load_dotenv()

MONGODB_URI = os.getenv("MONGODB_URI")


async def ask_claude(
    context,
    question,
    model_id="us.anthropic.claude-3-5-sonnet-20241022-v2:0",
):
    """
    Asynchronously sends a question to the Claude AI model using the provided context and returns the model's response.

    Args:
        context (str): The context information to provide to the AI model.
        question (str): The question to ask the AI model.
        model_id (str, optional): The identifier of the Claude AI model to use. Defaults to "us.anthropic.claude-3-5-sonnet-20241022-v2:0".

    Returns:
        str: The response text from the AI model.

    Raises:
        botocore.exceptions.BotoCoreError: If there is an error with the AWS Boto3 client.
        botocore.exceptions.ClientError: If there is a client error when invoking the model.
    """
    client = boto3.client("bedrock-runtime", region_name="us-east-1")
    prompt = (
        "You are a highly capable AI assistant. Anwser the question using the following context:\n"
        f"{context}\n\n"
        "Question:\n"
        f"{question}"
    )

    # Format the request payload using the model's native structure.
    native_request = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 8192,
        "temperature": 0.7,
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": prompt}],
            }
        ],
    }

    # Convert the native request to JSON.
    request = json.dumps(native_request)
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None, lambda: client.invoke_model(modelId=model_id, body=request)
    )
    model_response = json.loads(response["body"].read())
    response_text = model_response["content"][0]["text"]
    return response_text


async def process_request(messages, history):
    """
    Process incoming messages and generate a response using MongoDB Atlas and Claude AI.

    Args:
        messages (list): A list of messages to process.
        history (list): A list of previous message history.

    Yields:
        str: The response generated by Claude AI or an error message if an exception occurs.

    Raises:
        Exception: If there is an error during processing.

    Notes:
        - This function uses MongoDB Atlas for hybrid search.
        - The response is generated asynchronously using Claude AI.
    """
    # Initialize an empty string for documents
    # Print the incoming messages for debugging
    # If there are messages, perform a MongoDB hybrid search
    # Print the retrieved documents for debugging
    # Generate a response using Claude AI and yield it
    # Handle any exceptions and yield an error message
    try:
        docs = ""
        print(messages)
        if messages:
            docs = mongodb_atlas_retriever_tools.MongoDBAtlasRetrieverTools.mongodb_hybrid_search(
                messages
            )
            print(docs)
            response = await ask_claude(docs, messages)
            yield response
        return
    except Exception as error:
        print(error)
        yield "There was an error.\n" + str(error)


custom_css = """
           
            .message-row img {
                margin: 0px !important;
            }

            .avatar-container img {
            padding: 0px !important;
            }

            footer {visibility: hidden}; 
        """


def print_like_dislike(x: gr.LikeData):
    print(x.index, x.value, x.liked)
    return


with gr.Blocks(
    head="",
    fill_height=True,
    fill_width=True,
    css=custom_css,
    title="VisualAIze",
    theme=gr.themes.Soft(primary_hue=gr.themes.colors.green),
) as demo:
    m("""<center><h1>Ask Me!</h1></center><br/>""")
    bot = gr.Chatbot(
        elem_id="chatbot",
        bubble_full_width=True,
        type="messages",
        autoscroll=True,
        avatar_images=[
            "https://ca.slack-edge.com/E01C4Q4H3CL-U04D0GXU2B1-g1a101208f57-192",
            "https://ca.slack-edge.com/E01C4Q4H3CL-U04D0GXU2B1-g1a101208f57-192",
        ],
        show_copy_button=True,
        render=False,
        min_height="700px",
        label="Type your query...",
    )
    bot.like(print_like_dislike, None, None, like_user_message=False)

    CI = gr.ChatInterface(
        fn=process_request,
        chatbot=bot,
        type="messages",
        title="",
        description="",
        multimodal=False,
        fill_height=True,
        show_progress=False,
        concurrency_limit=None,
    )
